from pyspark.sql import SparkSession, Window
from pyspark.sql import functions as F
from pyspark.sql import types as T



spark = SparkSession\
    .builder\
    .master('local[*]')\
    .appName('ex4_anomalies_detection')\
    .config('spark.driver.memory','4g')\
    .getOrCreate()

all_history_window = Window.partitionBy(F.col('carrier')).orderBy(F.col('flight_date'))

flight_df = spark.read.parquet('s3a://spark/data/transformed/flights/')
flight_df.cache()



avg_delay_df = flight_df\
            .withColumn(
                'avg_till_now',
                F.avg('arr_delay').over(all_history_window)
            )

deviation_df = avg_delay_df\
                .withColumn(
                    'avg_diff_percent',
                    F.abs(F.col('arr_delay')/F.col('avg_till_now'))
                )

deviation_df.where(F.col('avg_diff_percent') > F.lit(3.0)).show()
flight_df.unpersist()

spark.stop()